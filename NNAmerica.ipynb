{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmOYTLZ4/piDrsBsKGgcsn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcoWeinzettel/projectdatascience/blob/main/NNAmerica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('ausgabe.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_filtered = df[[\"date\",\"tmin\",\"tmax\"]]\n",
        "\n",
        "df_filtered= df_filtered.dropna()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X=df_filtered[[\"date\"]].values\n",
        "y=df_filtered[[\"tmin\",\"tmax\"]].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_dim=1),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(2)])\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "#die 10 steht dafür dass wenn bei 10 aufeinanderfolgenden losses nix verbessert wird stoppt er die durchführungen\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "specific_date = np.array([[20240620]])\n",
        "\n",
        "prediction = model.predict(specific_date)\n",
        "\n",
        "print(\"Vorhersage für das Datum 20231017:\")\n",
        "print(\"tavg Vorhersage:\", prediction[0, 0])\n",
        "print(\"tmin Vorhersage:\", prediction[0, 1])\n",
        "print(\"tmax Vorhersage:\", prediction[0, 2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGsFqsssFdYX",
        "outputId": "02213651-64b6-4159-e333-9779765101c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23438/23438 [==============================] - 70s 3ms/step - loss: 135618832.0000 - val_loss: 254937280.0000\n",
            "Epoch 2/100\n",
            "23438/23438 [==============================] - 74s 3ms/step - loss: 18847452.0000 - val_loss: 37651.6250\n",
            "Epoch 3/100\n",
            "23438/23438 [==============================] - 86s 4ms/step - loss: 7456224.5000 - val_loss: 831763.6250\n",
            "Epoch 4/100\n",
            "23438/23438 [==============================] - 78s 3ms/step - loss: 4580502.5000 - val_loss: 213.4983\n",
            "Epoch 5/100\n",
            "23438/23438 [==============================] - 90s 4ms/step - loss: 1617942.1250 - val_loss: 269.0341\n",
            "Epoch 6/100\n",
            "23438/23438 [==============================] - 78s 3ms/step - loss: 629848.1875 - val_loss: 11415.2158\n",
            "Epoch 7/100\n",
            "23438/23438 [==============================] - 81s 3ms/step - loss: 13542.3242 - val_loss: 211.2871\n",
            "Epoch 8/100\n",
            "23438/23438 [==============================] - 87s 4ms/step - loss: 115.8151 - val_loss: 91.6511\n",
            "Epoch 9/100\n",
            "23438/23438 [==============================] - 76s 3ms/step - loss: 91.6134 - val_loss: 91.6492\n",
            "Epoch 10/100\n",
            "23438/23438 [==============================] - 74s 3ms/step - loss: 91.6137 - val_loss: 91.6515\n",
            "Epoch 11/100\n",
            "23438/23438 [==============================] - 78s 3ms/step - loss: 91.6136 - val_loss: 91.6515\n",
            "Epoch 12/100\n",
            "23438/23438 [==============================] - 70s 3ms/step - loss: 91.6131 - val_loss: 91.6499\n",
            "Epoch 13/100\n",
            "23438/23438 [==============================] - 80s 3ms/step - loss: 91.6129 - val_loss: 91.6518\n",
            "Epoch 14/100\n",
            "23438/23438 [==============================] - 77s 3ms/step - loss: 91.6133 - val_loss: 91.6494\n",
            "Epoch 15/100\n",
            "23438/23438 [==============================] - 87s 4ms/step - loss: 91.6129 - val_loss: 91.6507\n",
            "Epoch 16/100\n",
            "23438/23438 [==============================] - 77s 3ms/step - loss: 91.6130 - val_loss: 91.6497\n",
            "Epoch 17/100\n",
            "23438/23438 [==============================] - 75s 3ms/step - loss: 91.6132 - val_loss: 91.6504\n",
            "Epoch 18/100\n",
            "23438/23438 [==============================] - 89s 4ms/step - loss: 91.6125 - val_loss: 91.6500\n",
            "Epoch 19/100\n",
            "23432/23438 [============================>.] - ETA: 0s - loss: 91.6145"
          ]
        }
      ]
    }
  ]
}